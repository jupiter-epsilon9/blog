<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog Jupitera</title>
    <link>http://jupiter.098.pl/tags/proxy/index.xml</link>
    <description>Recent content on Blog Jupitera</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pl-pl</language>
    <atom:link href="http://jupiter.098.pl/tags/proxy/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Dostrajanie serwera squid</title>
      <link>http://jupiter.098.pl/posts/dostrajanie-serwera-squid/</link>
      <pubDate>Wed, 03 Apr 2013 11:35:47 +0100</pubDate>
      
      <guid>http://jupiter.098.pl/posts/dostrajanie-serwera-squid/</guid>
      <description>&lt;p&gt;Moje przygody z serwerem Squid i rozwiązania problemów, jakie napotkałem podczas jego użytkowania.
Serwer Squid w wersji 3.1.10, system operacyjny CentOS6.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;komunikat-possible-syn-flooding&#34;&gt;Komunikat &amp;ldquo;possible SYN flooding&amp;rdquo;&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;kernel: possible SYN flooding on port 3128. Sending cookies.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Wiadomość pojawia się, gdy kolejka &lt;em&gt;SYN backlog&lt;/em&gt; jest pełna. Jeżeli nie jest to atak &lt;em&gt;SYN flood&lt;/em&gt;, tylko na serwerze jest duży ruch, to należy zwiększyć tcp_max_syn_backlog.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@proxy ~]# cat /proc/sys/net/ipv4/tcp_max_syn_backlog
262144
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;błędy-page-allocation-failure&#34;&gt;Błędy &amp;ldquo;Page Allocation Failure&amp;rdquo;&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;swapper: page allocation failure. order:1, mode:0x20&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Rozwiązane poprzez zwiększenie parametru min_free_kbytes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@proxy ~]# echo 540732 &amp;gt; /proc/sys/vm/min_free_kbytes
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Re: Problems with swap? &amp;ldquo;swapper: page allocation failure. order:3, mode:0x4020&amp;rdquo;&lt;/p&gt;

&lt;p&gt;teddy_bteddy_b 29 Oct 2010, 21:09&lt;/p&gt;

&lt;p&gt;The page allocation failures are not just happening out of nowhere… When posting about such issues, it
would help to tell what you run either on your router, or on the connected clients, and what is your
router model. The most probable reason for these errors are running unrestricted torrents (which is
never a good idea), or other network activity generating lots and lots of connections and making NAT
to work hard.&lt;/p&gt;

&lt;p&gt;The best way to deal with these errors is to put restrictions on the processes that cause them - i.e.
for torrents it&amp;rsquo;s to limit the number of connections and bandwidth. If you&amp;rsquo;re unable or not willing to
make these restrictions for any reason, you can also try to increase the value in
&amp;ldquo;/proc/sys/vm/min_free_kbytes&amp;rdquo; - that should help to reduce the number of these errors (the more the
number, the less errors you will see, but it will also decrease the memory available for user space
applications).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;komunikat-protocol-not-available-w-cache-log-squid-a&#34;&gt;Komunikat &amp;ldquo;Protocol not available&amp;rdquo; w cache.log Squid&amp;rsquo;a&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;/var/log/squid/cache.log&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2011/01/04 11:03:38| IpIntercept.cc(137) NetfilterInterception: NF getsockopt(SO_ORIGINAL_DST) failed&amp;quot; on FD 12: (92) Protocol not available
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Problem pojawia się w przypadku gdy NAT jest na innym hoście niż SQUID. Poleca się instalować squid oraz NAT na tym samym hoscie. Załadowanie modułu śledzącego połączenia rozwiązało problem i komunikat zniknął.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;modprobe ip_conntrack
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;komunikat-nf-conntrack-table-full-dropping-packet&#34;&gt;Komunikat nf_conntrack: table full, dropping packet&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;nf_conntrack: table full, dropping packet&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@proxy ~]# echo 131072 &amp;gt; /proc/sys/net/nf_conntrack_max
[root@proxy ~]# echo 240 &amp;gt;  /proc/sys/net/netfilter/nf_conntrack_generic_timeout
[root@proxy ~]# echo 108000 &amp;gt;  /proc/sys/net/netfilter/nf_conntrack_tcp_timeout_established
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;zbyt-mała-ilość-deskryptorów&#34;&gt;Zbyt mała ilość deskryptorów&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;WARNING! Your cache is running out of filedescriptors&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Należy zwiększyć ilość deskryptorów w systemie i w Squid&amp;rsquo;zie:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vi /etc/security/limits.conf

dodano limit 32768
*               -       nofile          32768
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wylogowanie/zalogowanie do konsoli&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ulimit -a | grep &#39;open files&#39;
open files                      (-n) 32768
vi /etc/squid/squid.conf
max_filedesc 24567
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ostrzeżenie-disk-space-over-limit&#34;&gt;Ostrzeżenie &amp;ldquo;Disk space over limit&amp;rdquo;&lt;/h2&gt;

&lt;p&gt;W logach pojawił się komunikat świadczący o tym, że cache squida jest większe niż przydzielona wielkość.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;WARNING: Disk space over limit: 16777424 KB &amp;gt; 16777216 KB&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bugs.contribs.org/show_bug.cgi?id=664&#34;&gt;http://bugs.contribs.org/show_bug.cgi?id=664&lt;/a&gt; &lt;br&gt;
&lt;a href=&#34;http://bugs.contribs.org/show_bug.cgi?id=664#c3&#34;&gt;http://bugs.contribs.org/show_bug.cgi?id=664#c3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Komunikat oznacza, że rozmiar cache jest większy od ustawionego w konfiguracji. Być może na skutek nieprawidłowego zamknięcia Squid nie ma w bazie informacji o wszystkich plikach, które są w cache.&lt;/p&gt;

&lt;p&gt;Problem można rozwiązać np poprzez zwiększenie pojemności cache&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vi /etc/squid/squid.conf
cache_dir aufs /cache 32768 32 512
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wszystkie-sockety-zostały-zużyte&#34;&gt;Wszystkie sockety zostały zużyte&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;CommBind: Cannot bind socket FD 98 to *:0: (98) Address already in use&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Należy zwiększyć zakres dostępnych portów. Od 1024 do 65000&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;net.ipv4.ip_local_port_range=1024 65000
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ustawienia-tcp-keepalive&#34;&gt;Ustawienia TCP_KEEPALIVE&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://tldp.org/HOWTO/TCP-Keepalive-HOWTO/usingkeepalive.html&#34;&gt;http://tldp.org/HOWTO/TCP-Keepalive-HOWTO/usingkeepalive.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo 60 &amp;gt; /proc/sys/net/ipv4/tcp_keepalive_time
echo 3 &amp;gt; /proc/sys/net/ipv4/tcp_keepalive_probes
echo 50 &amp;gt; /proc/sys/net/ipv4/tcp_keepalive_intvl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Jeżeli połączenie nie odpowiada przez 60 sekund zacznij wysyłać próby, łącznie 3 co 50 sekund. Jeżeli żadna się nie powiedzie, to uznaj połączenie za martwe.&lt;/p&gt;

&lt;p&gt;Ustawienie na stałę w /etc/sysctl.conf&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;net.ipv4.tcp_keepalive_time = 60
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_keepalive_intvl = 50
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;obrazek w nagłówku: www.cwcs.co.uk&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>